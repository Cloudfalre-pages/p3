---
title: 'Debunking popular character.ai claims'
description: 'Fairly in-depth blog post debunking claims made about character.ai'
date: '2023-07-23'
categories:
    - ai
    - cloudflare
published: true
author: 'dromzeh'
---

## What even is character.ai?

tldr: character.ai is a website which allows for users to create their own "characters", and then talk to them using trained AI models.

## What even happened?

As of recent, character.ai has been under fire on social media, mainly TikTok, for various reasons. Misinformation is often spread on social media platforms about all sorts of things, and character.ai is no exception, people tend to believe what they see on social media, and don't bother to do any research themselves. This post will be debunking all claims made about character.ai, and explaining why they're false.

Note: this post has been edited for clarity and to add more information on the 14th August 2023.

## character.ai is "purposely rate limiting users" to buy a subscription

This should be self-explantory on why rate limiting is a thing, but I'll explain it anyway.

character.ai offers a free tier, just like thousands of services which exist. The nature of pricing any popular service is that you have to make money to be able to keep the service running, and to be able to pay for the servers which run the service as well as the people who work on the service.

Rate limiting exists to allow for all users to be able to use the site, regardless of whether they have a subscription or not. If rate limiting didn't exist, then the site would be unusable for everyone, as the servers would be overloaded.

## Being "banned" from character.ai

Another common claim is that users are being unknowingly "banned" from character.ai for no reason, this is false.

People are mistaking IP blocks, used by Cloudflare, for being banned. This can be caused by using something like a VPN, or by using a shared IP address, which has been banned. You're expected to be banned if you break their terms of service, which is a reasonable thing to do.

## Prompt Engineering Misunderstanding

Prompt engineering is the process of creating a prompt which will be fed into an AI model. This helps to create a more realistic response from the AI model.

Prompt engineering is somehow being mistaken for programming languages, such as Python, which is completely false. Prompt engineering is just a way of creating a prompt, which will be fed into an AI model. It's not a programming language.

Markdown is a markup language, and may also be used to recieve more realistic responses from the AI model, but it's not a programming language either.

character.ai uses markdown to format text, and to allow for users to create more realistic responses from their AI models.

There is a method of hiding text in markdown using invisible embeds. Using this, you can hide text in markdown, which will be invisible to the user, but will still be fed into the AI model, allowing for more realistic responses without ruining the overall "immersion" of the conversation.

## Slow response times

Slow response times are expected to exist, when you have a platform which is being used by thousands of users at once, and is using AI models to generate responses. The amount of processing power required to do this is immense, and is not something which can be done instantly.

### The Filter's effect on response times

Responses from the AI model are filtered to remove any offensive content, this is done to prevent users from being able to use the AI model to create offensive content, which is a reasonable thing to do. The filter, will of course, cause a delay in the response time, as the response has to be filtered before being sent to the user.

## Alternatives and their security

Not everyone is happy with character.ai's "filter", stating it's too "strict" or the response times are too long, leading them to go to alternative platforms which don't have a filter.

These users are not taking into account the security of these platforms, and the fact that they are not being filtered. This is a major security risk, as these platforms could be used to create offensive content, which could be used to harass people.

### Case Study 1: janitor.ai

janitor.ai is a platform which is similar to character.ai, but does not have a filter, thousands of users switched to janitor.ai to escape said filter.

There was recently a databreach within one of janitor.ai's "AI providers", this led to google docs of user's sensitive data being leaked within discord servers.

This shows that the safety of alternative platforms is not guaranteed, and that character.ai is overall a much safer option.

## Conclusion

character.ai is a safe platform, which is being unfairly targeted by social media, and is being unfairly compared to other platforms which are not as safe as character.ai. Users shouldn't make assumptions about a platform without doing any research beforehand.
